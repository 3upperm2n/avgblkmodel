{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Motivation:\n",
    "    \n",
    "Given the information on gpu and kernel, model the concurrent kernel runtime.\n",
    "\n",
    "**Shortcomings**:\n",
    "* assume the kernels are in 1D grid\n",
    "* the input for the model should be a list of all the kernels in N cuda streams. Right now, we assume the two kernels are from two different cuda streams, which seems confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**New**:\n",
    "\n",
    "* the coming kernel starting time can be adjustable\n",
    "* warp modeling inside function, use global data trace table to keep track each trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**:\n",
    "    * two kernels have overlapping\n",
    "    * they have different starting time, instead of 0 as the default\n",
    "    * change the sm num to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy  # deep copy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DeviceInfo():\n",
    "    def __init__(self, sm_num=0, sharedmem_per_sm=0, reg_per_sm=0, maxthreads_per_sm=0):\n",
    "        self.sm_num = sm_num\n",
    "        self.sharedmem_per_sm = sharedmem_per_sm # bytes\n",
    "        self.reg_per_sm = reg_per_sm\n",
    "        self.maxthreads_per_sm = maxthreads_per_sm\n",
    "        \n",
    "class KernelInfo():\n",
    "    def __init__(self, blockDim=0, gridDim=0, reg_per_thread=0, sharedmem_per_blk=0, runtime_ms = 0, start = 0):\n",
    "        self.blockDim = blockDim\n",
    "        self.gridDim = gridDim\n",
    "        self.reg_per_thread = reg_per_thread\n",
    "        self.sharedmem_per_blk =  sharedmem_per_blk\n",
    "        self.runtime_ms = runtime_ms\n",
    "        self.start_ms = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MaxBLK_Per_SM(Gpu, Kern):\n",
    "    \"\"\"\n",
    "    Compute the max blocks on one SM\n",
    "    \"\"\"\n",
    "    warp_size = 32\n",
    "    DeviceLimit = Gpu.maxthreads_per_sm / 32\n",
    "    \n",
    "    blocks_by_sm = DeviceLimit\n",
    "    \n",
    "    if Kern.sharedmem_per_blk > 0:\n",
    "        blocks_by_sm = floor(Gpu.sharedmem_per_sm / float(Kern.sharedmem_per_blk)) # int operation\n",
    "        \n",
    "    blocks_by_reg = floor(Gpu.reg_per_sm / float(Kern.reg_per_thread * Kern.blockDim))\n",
    "    \n",
    "    blocks_by_threads = floor(Gpu.maxthreads_per_sm / float(Kern.blockDim))\n",
    "    \n",
    "    # maxblks_per_sm\n",
    "    return min([blocks_by_sm, blocks_by_reg, blocks_by_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_avgblktime(Gpu, kernel):\n",
    "    max_blk_per_sm = MaxBLK_Per_SM(Gpu, kernel)\n",
    "    print('max blk per sm = {}'.format(max_blk_per_sm))\n",
    "    \n",
    "    block_per_iteration = Gpu.sm_num * max_blk_per_sm\n",
    "    iterations = ceil(kernel.gridDim / block_per_iteration) # total iterations\n",
    "    avg_blk_time = kernel.runtime_ms / float(iterations)\n",
    "    \n",
    "    return avg_blk_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gtx950 = DeviceInfo()\n",
    "gtx950.sm_num = 2\n",
    "gtx950.sharedmem_per_sm = 49152\n",
    "gtx950.reg_per_sm = 65536\n",
    "gtx950.maxthreads_per_sm = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup kernel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simulate kernel number\n",
    "kernel_num = 2\n",
    "\n",
    "kernels = [KernelInfo() for i in range(kernel_num)]\n",
    "\n",
    "kernels[0].blockDim = 256\n",
    "kernels[0].gridDim = 10\n",
    "kernels[0].reg_per_thread = 28\n",
    "kernels[0].sharedmem_per_blk= 0\n",
    "kernels[0].runtime_ms = 0.056961\n",
    "kernels[0].start_ms = 0.200611                                      # run the kernel at the beginning  \n",
    "\n",
    "kernels[1].blockDim = 256\n",
    "kernels[1].gridDim = 10\n",
    "kernels[1].reg_per_thread = 28\n",
    "kernels[1].sharedmem_per_blk= 0\n",
    "kernels[1].runtime_ms = 0.056961\n",
    "kernels[1].start_ms = 0.23682 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### compute average block execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max blk per sm = 8.0\n",
      "max blk per sm = 8.0\n"
     ]
    }
   ],
   "source": [
    "avg_blk_time_list = []\n",
    "\n",
    "for kid in range(kernel_num):\n",
    "    avg_blk_time_list.append(compute_avgblktime(gtx950, kernels[kid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056961, 0.056961]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_blk_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now we model the multiple kernel concurrent execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class sm_stat:\n",
    "    def __init__(self, thread=0, reg=0, sharedmem = 0, full=0, batch = 1):\n",
    "        self.thread = thread\n",
    "        self.reg= reg\n",
    "        self.sharedmem = sharedmem\n",
    "        self.full = full\n",
    "        self.batch = batch\n",
    "\n",
    "    def init(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch = 1\n",
    "    \n",
    "    def replenish(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch += 1 # add\n",
    "        \n",
    "    def Rm(self, Kern):\n",
    "        \"\"\"\n",
    "        Remove the kernel block occupied resource by adding them back.\n",
    "        \"\"\"\n",
    "        self.thread += Kern.blockDim\n",
    "        self.reg += Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem += Kern.sharedmem_per_blk\n",
    "\n",
    "    def Allocate_block(self, Kern):\n",
    "        self.thread -= Kern.blockDim\n",
    "        self.reg -= Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem -= Kern.sharedmem_per_blk\n",
    "\n",
    "        \n",
    "def check_sm_resource(current_sm, block_info):\n",
    "    enough_thread = current_sm.thread >= block_info.blockDim\n",
    "    enough_reg = current_sm.reg >= (block_info.reg_per_thread * block_info.blockDim)\n",
    "    enough_sm = current_sm.sharedmem >= block_info.sharedmem_per_blk\n",
    "    \n",
    "    allocate = False\n",
    "    if enough_thread and enough_reg and enough_sm:\n",
    "        allocate = True\n",
    "    \n",
    "    return allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Search_block_start(df_sm_trace, current_kernel_id):\n",
    "    \"\"\"\n",
    "    Read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "    \"\"\"\n",
    "    \n",
    "    #df_active = df_sm_trace.loc[(df_sm_trace['active'] == 1) & (df_sm_trace['kernel_id'] == current_kernel_id)]\n",
    "    df_active = df_sm_trace.loc[df_sm_trace['active'] == 1]\n",
    "    \n",
    "       \n",
    "    if not df_active.empty:\n",
    "        blk2start = df_active['block_start'].max() # find the closest block\n",
    "\n",
    "        df_active_current_kernel = df_active.loc[df_active['kernel_id'] == current_kernel_id]\n",
    "        if not df_active_current_kernel.empty:\n",
    "            blk2start = df_active_current_kernel['block_start'].max()  # find the closest blk for current kernel\n",
    "    \n",
    "        return blk2start\n",
    "    else:\n",
    "        # when, on current sm, all the blocks are done/de-activated\n",
    "        # warning!!!\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modeling the execution and record the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init SM status\n",
    "sm_num = gtx950.sm_num\n",
    "sms = [sm_stat() for i in range(sm_num)]\n",
    "\n",
    "for i in range(sm_num):\n",
    "    sms[i].init(gtx950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a trace table to record all the block trace: using pd dataframe\n",
    "trace_table = pd.DataFrame(columns=['sm_id', 'block_id', 'block_start', 'block_end', 'batch_id', 'kernel_id', 'active'])\n",
    "\n",
    "# have a trace table for each sm\n",
    "sm_trace = [trace_table for x in range(gtx950.sm_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print len(sm_trace)\n",
    "# print sm_trace[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run the 1st kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# kern = kernels[0] # schedule current kernel on the device\n",
    "# kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "# print kernel_blocks\n",
    "# kern_start = kern.start_ms\n",
    "# print kern_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_sm2start(sm_trace_list, kern_start):\n",
    "    sm_num = len(sm_trace_list)\n",
    "    \n",
    "    AfterPrevKern = False\n",
    "    \n",
    "    empSM = 0\n",
    "    # case 1) there are no trace on each sm\n",
    "    for df_sm in sm_trace_list:\n",
    "        if df_sm.empty:\n",
    "            empSM = empSM + 1 # do nothing\n",
    "\n",
    "    if empSM == sm_num:\n",
    "        return 0, AfterPrevKern       \n",
    "    \n",
    "    # case 2ï¼‰ there are traces: \n",
    "    # by the time where the kernel starts, all the blocks are done already, use sm 0\n",
    "    max_t = 0\n",
    "    for df_sm in sm_trace_list:\n",
    "        cur_max = df_sm.block_end.max()\n",
    "        if cur_max > max_t:\n",
    "            max_t = cur_max\n",
    "            \n",
    "    if max_t <= kern_start:\n",
    "        AfterPrevKern = True\n",
    "        return 0, AfterPrevKern\n",
    "    else:\n",
    "        # case 3) : check currently active blocks\n",
    "        df_sm = sm_trace_list[0]\n",
    "        df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "        min_t = df_activeblk.block_end.min()\n",
    "        target_sm = 0\n",
    "        \n",
    "        for i in range(1,sm_num):\n",
    "            df_sm = sm_trace_list[i]\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            sm_blk_min = df_activeblk.block_end.min()\n",
    "            if sm_blk_min < min_t:\n",
    "                min_t = sm_blk_min\n",
    "                target_sm = i\n",
    "                \n",
    "        return target_sm, AfterPrevKern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cke_model(sms_, sm_trace_, kernels_):\n",
    "    # deep copy the input\n",
    "    # we need to return the resource and trace for each sm after modeling\n",
    "    sms = copy.deepcopy(sms_)\n",
    "    sm_trace = copy.deepcopy(sm_trace_)\n",
    "    kernels = copy.deepcopy(kernels_)\n",
    "    \n",
    "    kernel_num = len(kernels)\n",
    "    \n",
    "    # go through each kernel\n",
    "    for i in range(kernel_num):\n",
    "        kern = kernels[i] # schedule current kernel on the device\n",
    "\n",
    "        kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "    #     print kernel_blocks\n",
    "\n",
    "        kern_start = kern.start_ms\n",
    "        print('kern-{}:  start {}'.format(i, kern_start))\n",
    "\n",
    "        # 1) find the which sm to start\n",
    "        # 2) compute whether kernel_start happens before previous kernel ends or not\n",
    "        sm2start, AfterPrevKern = find_sm2start(sm_trace, kern_start)\n",
    "        print('sm2start : {}, AfterPrevKern {}'.format(sm2start, AfterPrevKern))\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Run after previous kernel\n",
    "        #---------------------------------------------------------\n",
    "        if AfterPrevKern:\n",
    "            # deactivate all the previous active blocks\n",
    "            myid = 0\n",
    "            for df_sm in sm_trace:\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                for index, row in df_activeblk.iterrows():     # find the row index of active blocks\n",
    "                    sm_trace[myid].loc[index]['active'] = 0    # deactivate \n",
    "                    sms[myid].Rm(kern)                         # free the block resource\n",
    "                    myid = myid + 1\n",
    "\n",
    "#         if i==0: break\n",
    "\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Continue current kernel\n",
    "        #---------------------------------------------------------\n",
    "        for bid in range(kernel_blocks):\n",
    "            sm_id = (bid + sm2start) % sm_num\n",
    "            print('kern-{}, blk-{}, sm_id {} '.format(i, bid, sm_id))\n",
    "\n",
    "            to_allocate_another_block = check_sm_resource(sms[sm_id], kern)\n",
    "            print('to_allocate_another_block {}'.format(to_allocate_another_block)) \n",
    "\n",
    "            #----------------------------------\n",
    "            # there is enough resource to host the current block\n",
    "            #----------------------------------\n",
    "            if to_allocate_another_block == True:\n",
    "                sms[sm_id].Allocate_block(kern)  # deduct resources on the current sm\n",
    "\n",
    "                #---------------------------------------\n",
    "                # register the block in the trace table\n",
    "                #---------------------------------------\n",
    "                block_start = None\n",
    "\n",
    "                offset = 0.0\n",
    "                if AfterPrevKern and bid < sm_num:  # Noted: only the 1st block will adjut the kern_start\n",
    "                    offset = kern_start\n",
    "\n",
    "                # if current sm trace table is empty, start from kernel_start\n",
    "                # else find the blocks that will end soon, and retire them\n",
    "                if sm_trace[sm_id].empty:\n",
    "                    block_start = kern_start # (fixed!)\n",
    "                else:\n",
    "                    # read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "                    block_start = Search_block_start(sm_trace[sm_id], i) + offset\n",
    "\n",
    "\n",
    "                block_end = block_start + avg_blk_time_list[i]\n",
    "\n",
    "                print('kern {} : block_start: {}, block_end: {}, block_start {}'.format(i, \n",
    "                                                                block_start, block_end, \n",
    "                                                                Search_block_start(sm_trace[sm_id], i)))\n",
    "                if bid == 0: break\n",
    "                    \n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "    #             if i==1 and bid == 0: \n",
    "    #                 print('block_start {}, block_end {}, kern_start {}'.format(block_start, block_end, kern_start))\n",
    "    #                 break\n",
    "\n",
    "                # add the current block info to the current sm\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start, # add the kern stat\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "\n",
    "            #-------------------------------------------\n",
    "            # There is no more resources to host the blk, consider SM is full now\n",
    "            # we need to (1) decide how many blks to retire (2) when to start current blk\n",
    "            if to_allocate_another_block == False:\n",
    "                # find out the active blocks on current sm\n",
    "                df_sm = sm_trace[sm_id]\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                df_loc = df_activeblk.copy(deep=True)\n",
    "\n",
    "                cur_activeblk_num = df_activeblk.shape[0]\n",
    "\n",
    "\n",
    "                for ii in range(cur_activeblk_num):\n",
    "                    # find out blocks ending soon\n",
    "                    blkend_min = df_loc['block_end'].min()\n",
    "                    df_blk2end = df_loc.loc[df_loc['block_end'] == blkend_min]\n",
    "\n",
    "                    # retire the blocks\n",
    "                    for index, row in df_blk2end.iterrows():\n",
    "                        sm_trace[sm_id].loc[index]['active'] = 0 \n",
    "                        sms[sm_id].Rm(kern) # free the block resource\n",
    "\n",
    "                    # enough to allocate a current block\n",
    "                    if check_sm_resource(sms[sm_id], kern):\n",
    "                        sms[sm_id].Allocate_block(kern)\n",
    "\n",
    "                        block_start = blkend_min # when prev blks end, current block starts\n",
    "                        block_end = block_start + avg_blk_time_list[i]     # add avgblktime for currrent kernel\n",
    "                        break # jump out of the loop\n",
    "                    else:\n",
    "                        # not enough to allocat another block, remove\n",
    "                        df_loc = df_sm.loc[df_sm['active'] == 1]\n",
    "\n",
    "    #             print('kernel {}'.format(i))\n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "                # update the trace table\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start,\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "            \n",
    "        # end of running blocks for current kernel        \n",
    "        if i==0: break\n",
    "            \n",
    "    #end of kernel iteration\n",
    "                \n",
    "    # return the updated sm resource and trace table\n",
    "    return sms, sm_trace\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kern-0:  start 0.200611\n",
      "sm2start : 0, AfterPrevKern False\n",
      "kern-0, blk-0, sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.200611, block_end: 0.257572, block_start 0.0\n"
     ]
    }
   ],
   "source": [
    "sms, sm_trace = cke_model(sms, sm_trace, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sm_id, block_id, block_start, block_end, batch_id, kernel_id, active]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sm_id, block_id, block_start, block_end, batch_id, kernel_id, active]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leiming/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.py:3179: UserWarning: Attempting to set identical bottom==top results\n",
      "in singular transformations; automatically expanding.\n",
      "bottom=0, top=0\n",
      "  'bottom=%s, top=%s') % (bottom, top))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEKCAYAAABOjWFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7face9e96e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Plot_sm_trace(df_sm):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # color to pick\n",
    "    color_list = ['r', 'k', 'b', 'g', 'c', 'm', 'y', '#cc0000', '#cc6600', 'cc9900',\n",
    "                  '#cc3300', '#cccc00', '#99cc00', '#66cc00', '#00cccc', '#0033cc', \n",
    "                  '#6600cc', '#cc00cc', '#ff99cc', 'ffcc00']\n",
    "    \n",
    "    total_color = len(color_list) \n",
    "    \n",
    "    kern_ids = df_sm['kernel_id'].unique()\n",
    "    \n",
    "    x0_dd = {}\n",
    "    x1_dd = {}\n",
    "    y0_dd = {}\n",
    "    \n",
    "    ylim_max = 0\n",
    "    \n",
    "    for kid in kern_ids:\n",
    "        offset = 0.1 * kid\n",
    "        df_kern = df_sm.loc[df_sm['kernel_id'] == kid] # get the data for current kernel on\n",
    "        df_kern['y_axis'] = pd.Series(np.arange(1,len(df_kern.index)+1) + offset, \n",
    "                                      index=df_kern.index) # adding y_axis label\n",
    "    \n",
    "        x0_dd[kid] = df_kern['block_start']\n",
    "        x1_dd[kid] = df_kern['block_end']\n",
    "        y0_dd[kid] = df_kern['y_axis']\n",
    "\n",
    "        current_ymax = max(df_kern['y_axis']) + 1\n",
    "    \n",
    "        if ylim_max < current_ymax:\n",
    "            ylim_max = current_ymax\n",
    "    \n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, ylim_max])\n",
    "\n",
    "    for kid in kern_ids:\n",
    "        cid = int(kid) % total_color\n",
    "        plt.hlines(y0_dd[kid], x0_dd[kid], x1_dd[kid], lw=2, color=color_list[cid])\n",
    "\n",
    "    \n",
    "                                \n",
    "# #     plt.title('Memory Bound')\n",
    "    plt.xlabel('Time(clocks)')\n",
    "    plt.ylabel('Blocks')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#---------------------\n",
    "# plot\n",
    "#---------------------\n",
    "df_sm = sm_trace[0]\n",
    "\n",
    "Plot_sm_trace(df_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
