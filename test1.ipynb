{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Motivation:\n",
    "    \n",
    "Given the information on gpu and kernel, model the concurrent kernel runtime.\n",
    "\n",
    "**Shortcomings**:\n",
    "* assume the kernels are in 1D grid\n",
    "* the input for the model should be a list of all the kernels in N cuda streams. Right now, we assume the two kernels are from two different cuda streams, which seems confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**New**:\n",
    "\n",
    "* the coming kernel starting time can be adjustable\n",
    "* warp modeling inside function, use global data trace table to keep track each trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**:\n",
    "    * two kernels have overlapping\n",
    "    * they have different starting time, instead of 0 as the default\n",
    "    * change the sm num to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy  # deep copy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DeviceInfo():\n",
    "    def __init__(self, sm_num=0, sharedmem_per_sm=0, reg_per_sm=0, maxthreads_per_sm=0):\n",
    "        self.sm_num = sm_num\n",
    "        self.sharedmem_per_sm = sharedmem_per_sm # bytes\n",
    "        self.reg_per_sm = reg_per_sm\n",
    "        self.maxthreads_per_sm = maxthreads_per_sm\n",
    "        \n",
    "class KernelInfo():\n",
    "    def __init__(self, blockDim=0, gridDim=0, reg_per_thread=0, sharedmem_per_blk=0, runtime_ms = 0, start = 0):\n",
    "        self.blockDim = blockDim\n",
    "        self.gridDim = gridDim\n",
    "        self.reg_per_thread = reg_per_thread\n",
    "        self.sharedmem_per_blk =  sharedmem_per_blk\n",
    "        self.runtime_ms = runtime_ms\n",
    "        self.start_ms = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MaxBLK_Per_SM(Gpu, Kern):\n",
    "    \"\"\"\n",
    "    Compute the max blocks on one SM\n",
    "    \"\"\"\n",
    "    warp_size = 32\n",
    "    DeviceLimit = Gpu.maxthreads_per_sm / 32\n",
    "    \n",
    "    blocks_by_sm = DeviceLimit\n",
    "    \n",
    "    if Kern.sharedmem_per_blk > 0:\n",
    "        blocks_by_sm = floor(Gpu.sharedmem_per_sm / float(Kern.sharedmem_per_blk)) # int operation\n",
    "        \n",
    "    blocks_by_reg = floor(Gpu.reg_per_sm / float(Kern.reg_per_thread * Kern.blockDim))\n",
    "    \n",
    "    blocks_by_threads = floor(Gpu.maxthreads_per_sm / float(Kern.blockDim))\n",
    "    \n",
    "    # maxblks_per_sm\n",
    "    return min([blocks_by_sm, blocks_by_reg, blocks_by_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_avgblktime(Gpu, kernel):\n",
    "    max_blk_per_sm = MaxBLK_Per_SM(Gpu, kernel)\n",
    "    print('max blk per sm = {}'.format(max_blk_per_sm))\n",
    "    \n",
    "    block_per_iteration = Gpu.sm_num * max_blk_per_sm\n",
    "    iterations = ceil(kernel.gridDim / block_per_iteration) # total iterations\n",
    "    avg_blk_time = kernel.runtime_ms / float(iterations)\n",
    "    \n",
    "    return avg_blk_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gtx950 = DeviceInfo()\n",
    "gtx950.sm_num = 2\n",
    "gtx950.sharedmem_per_sm = 49152\n",
    "gtx950.reg_per_sm = 65536\n",
    "gtx950.maxthreads_per_sm = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup kernel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simulate kernel number\n",
    "kernel_num = 2\n",
    "\n",
    "kernels = [KernelInfo() for i in range(kernel_num)]\n",
    "\n",
    "kernels[0].blockDim = 256\n",
    "kernels[0].gridDim = 10\n",
    "kernels[0].reg_per_thread = 28\n",
    "kernels[0].sharedmem_per_blk= 0\n",
    "kernels[0].runtime_ms = 0.056961\n",
    "kernels[0].start_ms = 0.200611                                      # run the kernel at the beginning  \n",
    "\n",
    "kernels[1].blockDim = 256\n",
    "kernels[1].gridDim = 10\n",
    "kernels[1].reg_per_thread = 28\n",
    "kernels[1].sharedmem_per_blk= 0\n",
    "kernels[1].runtime_ms = 0.056961\n",
    "kernels[1].start_ms = 0.23682 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### compute average block execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max blk per sm = 8.0\n",
      "max blk per sm = 8.0\n"
     ]
    }
   ],
   "source": [
    "avg_blk_time_list = []\n",
    "\n",
    "for kid in range(kernel_num):\n",
    "    avg_blk_time_list.append(compute_avgblktime(gtx950, kernels[kid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056961, 0.056961]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_blk_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now we model the multiple kernel concurrent execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class sm_stat:\n",
    "    def __init__(self, thread=0, reg=0, sharedmem = 0, full=0, batch = 1):\n",
    "        self.thread = thread\n",
    "        self.reg= reg\n",
    "        self.sharedmem = sharedmem\n",
    "        self.full = full\n",
    "        self.batch = batch\n",
    "\n",
    "    def init(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch = 1\n",
    "    \n",
    "    def replenish(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch += 1 # add\n",
    "        \n",
    "    def Rm(self, Kern):\n",
    "        \"\"\"\n",
    "        Remove the kernel block occupied resource by adding them back.\n",
    "        \"\"\"\n",
    "        self.thread += Kern.blockDim\n",
    "        self.reg += Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem += Kern.sharedmem_per_blk\n",
    "\n",
    "    def Allocate_block(self, Kern):\n",
    "        self.thread -= Kern.blockDim\n",
    "        self.reg -= Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem -= Kern.sharedmem_per_blk\n",
    "\n",
    "        \n",
    "def check_sm_resource(current_sm, block_info):\n",
    "    enough_thread = current_sm.thread >= block_info.blockDim\n",
    "    enough_reg = current_sm.reg >= (block_info.reg_per_thread * block_info.blockDim)\n",
    "    enough_sm = current_sm.sharedmem >= block_info.sharedmem_per_blk\n",
    "    \n",
    "    allocate = False\n",
    "    if enough_thread and enough_reg and enough_sm:\n",
    "        allocate = True\n",
    "    \n",
    "    return allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Search_block_start(df_sm_trace, current_kernel_id):\n",
    "    \"\"\"\n",
    "    Read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "    \"\"\"\n",
    "    \n",
    "    #df_active = df_sm_trace.loc[(df_sm_trace['active'] == 1) & (df_sm_trace['kernel_id'] == current_kernel_id)]\n",
    "    df_active = df_sm_trace.loc[df_sm_trace['active'] == 1]\n",
    "    \n",
    "       \n",
    "    if not df_active.empty:\n",
    "        blk2start = df_active['block_start'].max() # find the closest block\n",
    "\n",
    "        df_active_current_kernel = df_active.loc[df_active['kernel_id'] == current_kernel_id]\n",
    "        if not df_active_current_kernel.empty:\n",
    "            blk2start = df_active_current_kernel['block_start'].max()  # find the closest blk for current kernel\n",
    "    \n",
    "        return blk2start\n",
    "    else:\n",
    "        # when, on current sm, all the blocks are done/de-activated\n",
    "        # warning!!!\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modeling the execution and record the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init SM status\n",
    "sm_num = gtx950.sm_num\n",
    "sms = [sm_stat() for i in range(sm_num)]\n",
    "\n",
    "for i in range(sm_num):\n",
    "    sms[i].init(gtx950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a trace table to record all the block trace: using pd dataframe\n",
    "trace_table = pd.DataFrame(columns=['sm_id', 'block_id', 'block_start', 'block_end', 'batch_id', 'kernel_id', 'active'])\n",
    "\n",
    "# have a trace table for each sm\n",
    "sm_trace = [trace_table for x in range(gtx950.sm_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print len(sm_trace)\n",
    "# print sm_trace[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run the 1st kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# kern = kernels[0] # schedule current kernel on the device\n",
    "# kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "# print kernel_blocks\n",
    "# kern_start = kern.start_ms\n",
    "# print kern_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_sm2start(sm_trace_list, kern_start):\n",
    "    sm_num = len(sm_trace_list)\n",
    "    \n",
    "    AfterPrevKern = False\n",
    "    \n",
    "    empSM = 0\n",
    "    # case 1) there are no trace on each sm\n",
    "    for df_sm in sm_trace_list:\n",
    "        if df_sm.empty:\n",
    "            empSM = empSM + 1 # do nothing\n",
    "\n",
    "    if empSM == sm_num:\n",
    "        return 0, AfterPrevKern       \n",
    "    \n",
    "    # case 2ï¼‰ there are traces: \n",
    "    # by the time where the kernel starts, all the blocks are done already, use sm 0\n",
    "    max_t = 0\n",
    "    for df_sm in sm_trace_list:\n",
    "        cur_max = df_sm.block_end.max()\n",
    "        if cur_max > max_t:\n",
    "            max_t = cur_max\n",
    "            \n",
    "    if max_t <= kern_start:\n",
    "        AfterPrevKern = True\n",
    "        return 0, AfterPrevKern\n",
    "    else:\n",
    "        # case 3) : check currently active blocks\n",
    "        df_sm = sm_trace_list[0]\n",
    "        df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "        min_t = df_activeblk.block_end.min()\n",
    "        target_sm = 0\n",
    "        \n",
    "        for i in range(1,sm_num):\n",
    "            df_sm = sm_trace_list[i]\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            sm_blk_min = df_activeblk.block_end.min()\n",
    "            if sm_blk_min < min_t:\n",
    "                min_t = sm_blk_min\n",
    "                target_sm = i\n",
    "                \n",
    "        return target_sm, AfterPrevKern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cke_model(sms_, sm_trace_, kernels_):\n",
    "    # deep copy the input\n",
    "    # we need to return the resource and trace for each sm after modeling\n",
    "    sms = copy.deepcopy(sms_)\n",
    "    sm_trace = copy.deepcopy(sm_trace_)\n",
    "    kernels = copy.deepcopy(kernels_)\n",
    "    \n",
    "    kernel_num = len(kernels)\n",
    "    \n",
    "    # go through each kernel\n",
    "    for i in range(kernel_num):\n",
    "        kern = kernels[i] # schedule current kernel on the device\n",
    "\n",
    "        kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "    #     print kernel_blocks\n",
    "\n",
    "        kern_start = kern.start_ms\n",
    "        print('kern-{}: start {}'.format(i, kern_start))\n",
    "\n",
    "        # 1) find the which sm to start\n",
    "        # 2) compute whether kernel_start happens before previous kernel ends or not\n",
    "        sm2start, AfterPrevKern = find_sm2start(sm_trace, kern_start)\n",
    "        print('sm2start : {}, AfterPrevKern {}'.format(sm2start, AfterPrevKern))\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Run after previous kernel\n",
    "        #---------------------------------------------------------\n",
    "        if AfterPrevKern:\n",
    "            # deactivate all the previous active blocks\n",
    "            myid = 0\n",
    "            for df_sm in sm_trace:\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                for index, row in df_activeblk.iterrows():     # find the row index of active blocks\n",
    "                    sm_trace[myid].loc[index]['active'] = 0    # deactivate \n",
    "                    sms[myid].Rm(kern)                         # free the block resource\n",
    "                    myid = myid + 1\n",
    "\n",
    "#         if i==0: break\n",
    "\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Continue current kernel\n",
    "        #---------------------------------------------------------\n",
    "        for bid in range(kernel_blocks):\n",
    "            sm_id = (bid + sm2start) % sm_num\n",
    "            print('sm_id {} '.format(sm_id))\n",
    "\n",
    "            to_allocate_another_block = check_sm_resource(sms[sm_id], kern)\n",
    "            print('to_allocate_another_block {}'.format(to_allocate_another_block)) \n",
    "\n",
    "            #----------------------------------\n",
    "            # there is enough resource to host the current block\n",
    "            #----------------------------------\n",
    "            if to_allocate_another_block == True:\n",
    "                sms[sm_id].Allocate_block(kern)  # deduct resources on the current sm\n",
    "\n",
    "                #---------------------------------------\n",
    "                # register the block in the trace table\n",
    "                #---------------------------------------\n",
    "                block_start = None\n",
    "\n",
    "                offset = 0.0\n",
    "                if AfterPrevKern and bid < sm_num:  # Noted: only the 1st block will adjut the kern_start\n",
    "                    offset = kern_start\n",
    "\n",
    "                # if current sm trace table is empty, start from kernel_start\n",
    "                # else find the blocks that will end soon, and retire them\n",
    "                if sm_trace[sm_id].empty:\n",
    "                    block_start = kern_start # (fixed!)\n",
    "                else:\n",
    "                    # read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "                    block_start = Search_block_start(sm_trace[sm_id], i) + offset\n",
    "\n",
    "\n",
    "                block_end = block_start + avg_blk_time_list[i]\n",
    "\n",
    "                print('kern {} : block_start: {}, block_end: {}, block_start {}'.format(i, \n",
    "                                                                block_start, block_end, \n",
    "                                                                Search_block_start(sm_trace[sm_id], i)))\n",
    "                if i==0: break\n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "    #             if i==1 and bid == 0: \n",
    "    #                 print('block_start {}, block_end {}, kern_start {}'.format(block_start, block_end, kern_start))\n",
    "    #                 break\n",
    "\n",
    "                # add the current block info to the current sm\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start, # add the kern stat\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "\n",
    "            #-------------------------------------------\n",
    "            # There is no more resources to host the blk, consider SM is full now\n",
    "            # we need to (1) decide how many blks to retire (2) when to start current blk\n",
    "            if to_allocate_another_block == False:\n",
    "                # find out the active blocks on current sm\n",
    "                df_sm = sm_trace[sm_id]\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                df_loc = df_activeblk.copy(deep=True)\n",
    "\n",
    "                cur_activeblk_num = df_activeblk.shape[0]\n",
    "\n",
    "\n",
    "                for ii in range(cur_activeblk_num):\n",
    "                    # find out blocks ending soon\n",
    "                    blkend_min = df_loc['block_end'].min()\n",
    "                    df_blk2end = df_loc.loc[df_loc['block_end'] == blkend_min]\n",
    "\n",
    "                    # retire the blocks\n",
    "                    for index, row in df_blk2end.iterrows():\n",
    "                        sm_trace[sm_id].loc[index]['active'] = 0 \n",
    "                        sms[sm_id].Rm(kern) # free the block resource\n",
    "\n",
    "                    # enough to allocate a current block\n",
    "                    if check_sm_resource(sms[sm_id], kern):\n",
    "                        sms[sm_id].Allocate_block(kern)\n",
    "\n",
    "                        block_start = blkend_min # when prev blks end, current block starts\n",
    "                        block_end = block_start + avg_blk_time_list[i]     # add avgblktime for currrent kernel\n",
    "                        break # jump out of the loop\n",
    "                    else:\n",
    "                        # not enough to allocat another block, remove\n",
    "                        df_loc = df_sm.loc[df_sm['active'] == 1]\n",
    "\n",
    "    #             print('kernel {}'.format(i))\n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "                # update the trace table\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start,\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "            \n",
    "    # return the updated sm resource and trace table\n",
    "    return sms, sm_trace\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kern-0: start 0.200611\n",
      "sm2start : 0, AfterPrevKern False\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.200611, block_end: 0.257572, block_start 0.0\n",
      "kern-1: start 0.23682\n",
      "sm2start : 0, AfterPrevKern False\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.23682, block_end: 0.293781, block_start 0.23682\n"
     ]
    }
   ],
   "source": [
    "sms, sm_trace = cke_model(sms, sm_trace, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sm_id  block_id  block_start  block_end  batch_id  kernel_id  active\n",
       "0    0.0       0.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "1    0.0       2.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "2    0.0       4.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "3    0.0       6.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "4    0.0       8.0      0.23682   0.293781       1.0        1.0     1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.23682</td>\n",
       "      <td>0.293781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sm_id  block_id  block_start  block_end  batch_id  kernel_id  active\n",
       "0    1.0       1.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "1    1.0       3.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "2    1.0       5.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "3    1.0       7.0      0.23682   0.293781       1.0        1.0     1.0\n",
       "4    1.0       9.0      0.23682   0.293781       1.0        1.0     1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+JLUCANfkhrxf/xYT36yi87lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7dcedc8f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Plot_sm_trace(df_sm):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # color to pick\n",
    "    color_list = ['r', 'k', 'b', 'g', 'c', 'm', 'y', '#cc0000', '#cc6600', 'cc9900',\n",
    "                  '#cc3300', '#cccc00', '#99cc00', '#66cc00', '#00cccc', '#0033cc', \n",
    "                  '#6600cc', '#cc00cc', '#ff99cc', 'ffcc00']\n",
    "    \n",
    "    total_color = len(color_list) \n",
    "    \n",
    "    kern_ids = df_sm['kernel_id'].unique()\n",
    "    \n",
    "    x0_dd = {}\n",
    "    x1_dd = {}\n",
    "    y0_dd = {}\n",
    "    \n",
    "    ylim_max = 0\n",
    "    \n",
    "    for kid in kern_ids:\n",
    "        offset = 0.1 * kid\n",
    "        df_kern = df_sm.loc[df_sm['kernel_id'] == kid] # get the data for current kernel on\n",
    "        df_kern['y_axis'] = pd.Series(np.arange(1,len(df_kern.index)+1) + offset, \n",
    "                                      index=df_kern.index) # adding y_axis label\n",
    "    \n",
    "        x0_dd[kid] = df_kern['block_start']\n",
    "        x1_dd[kid] = df_kern['block_end']\n",
    "        y0_dd[kid] = df_kern['y_axis']\n",
    "\n",
    "        current_ymax = max(df_kern['y_axis']) + 1\n",
    "    \n",
    "        if ylim_max < current_ymax:\n",
    "            ylim_max = current_ymax\n",
    "    \n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, ylim_max])\n",
    "\n",
    "    for kid in kern_ids:\n",
    "        cid = int(kid) % total_color\n",
    "        plt.hlines(y0_dd[kid], x0_dd[kid], x1_dd[kid], lw=2, color=color_list[cid])\n",
    "\n",
    "    \n",
    "                                \n",
    "# #     plt.title('Memory Bound')\n",
    "    plt.xlabel('Time(clocks)')\n",
    "    plt.ylabel('Blocks')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#---------------------\n",
    "# plot\n",
    "#---------------------\n",
    "df_sm = sm_trace[0]\n",
    "\n",
    "Plot_sm_trace(df_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
