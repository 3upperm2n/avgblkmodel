{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Motivation:\n",
    "    \n",
    "Given the information on gpu and kernel, model the concurrent kernel runtime.\n",
    "\n",
    "Shortcomings:\n",
    "* assume the kernels are in 1D grid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "New:\n",
    "    * the coming kernel starting time can be adjustable\n",
    "    * warp modeling inside function, use global data trace table to keep track each trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy  # deep copy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DeviceInfo():\n",
    "    def __init__(self, sm_num=0, sharedmem_per_sm=0, reg_per_sm=0, maxthreads_per_sm=0):\n",
    "        self.sm_num = sm_num\n",
    "        self.sharedmem_per_sm = sharedmem_per_sm # bytes\n",
    "        self.reg_per_sm = reg_per_sm\n",
    "        self.maxthreads_per_sm = maxthreads_per_sm\n",
    "        \n",
    "class KernelInfo():\n",
    "    def __init__(self, blockDim=0, gridDim=0, reg_per_thread=0, sharedmem_per_blk=0, runtime_ms = 0, start = 0):\n",
    "        self.blockDim = blockDim\n",
    "        self.gridDim = gridDim\n",
    "        self.reg_per_thread = reg_per_thread\n",
    "        self.sharedmem_per_blk =  sharedmem_per_blk\n",
    "        self.runtime_ms = runtime_ms\n",
    "        self.start_ms = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MaxBLK_Per_SM(Gpu, Kern):\n",
    "    \"\"\"\n",
    "    Compute the max blocks on one SM\n",
    "    \"\"\"\n",
    "    warp_size = 32\n",
    "    DeviceLimit = Gpu.maxthreads_per_sm / 32\n",
    "    \n",
    "    blocks_by_sm = DeviceLimit\n",
    "    \n",
    "    if Kern.sharedmem_per_blk > 0:\n",
    "        blocks_by_sm = floor(Gpu.sharedmem_per_sm / float(Kern.sharedmem_per_blk)) # int operation\n",
    "        \n",
    "    blocks_by_reg = floor(Gpu.reg_per_sm / float(Kern.reg_per_thread * Kern.blockDim))\n",
    "    \n",
    "    blocks_by_threads = floor(Gpu.maxthreads_per_sm / float(Kern.blockDim))\n",
    "    \n",
    "    # maxblks_per_sm\n",
    "    return min([blocks_by_sm, blocks_by_reg, blocks_by_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_avgblktime(Gpu, kernel):\n",
    "    max_blk_per_sm = MaxBLK_Per_SM(Gpu, kernel)\n",
    "    print('max blk per sm = {}'.format(max_blk_per_sm))\n",
    "    \n",
    "    block_per_iteration = Gpu.sm_num * max_blk_per_sm\n",
    "    iterations = ceil(kernel.gridDim / block_per_iteration) # total iterations\n",
    "    avg_blk_time = kernel.runtime_ms / float(iterations)\n",
    "    \n",
    "    return avg_blk_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gtx950 = DeviceInfo()\n",
    "gtx950.sm_num = 2\n",
    "gtx950.sharedmem_per_sm = 49152\n",
    "gtx950.reg_per_sm = 65536\n",
    "gtx950.maxthreads_per_sm = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup kernel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simulate kernel number\n",
    "kernel_num = 2\n",
    "\n",
    "kernels = [KernelInfo() for i in range(kernel_num)]\n",
    "\n",
    "kernels[0].blockDim = 512\n",
    "kernels[0].gridDim = 10\n",
    "kernels[0].reg_per_thread = 28\n",
    "kernels[0].sharedmem_per_blk= 0\n",
    "kernels[0].runtime_ms = 0.057249\n",
    "kernels[0].start_ms = 0.0                                      # run the kernel at the beginning  \n",
    "\n",
    "kernels[1].blockDim = 512\n",
    "kernels[1].gridDim = 10\n",
    "kernels[1].reg_per_thread = 28\n",
    "kernels[1].sharedmem_per_blk= 0\n",
    "kernels[1].runtime_ms = 0.057249 * 0.5   # assume half runtime\n",
    "# kernels[1].start_ms = kernels[0].start_ms + kernels[0].runtime_ms * 0.5  # run the kernel after kernel 0\n",
    "kernels[1].start_ms = kernels[0].start_ms + kernels[0].runtime_ms * 0.7  # run the kernel after kernel 0\n",
    "\n",
    "# kernels[2].blockDim = 512\n",
    "# kernels[2].gridDim = 10\n",
    "# kernels[2].reg_per_thread = 28\n",
    "# kernels[2].sharedmem_per_blk= 0\n",
    "# kernels[2].runtime_ms = 0.057249 * 2  # assume x2 runtime\n",
    "# kernels[1].start_ms = kernels[1].start_ms + kernels[1].runtime_ms    # run after kernel 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### compute average block execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max blk per sm = 4.0\n",
      "max blk per sm = 4.0\n"
     ]
    }
   ],
   "source": [
    "avg_blk_time_list = []\n",
    "\n",
    "for kid in range(kernel_num):\n",
    "    avg_blk_time_list.append(compute_avgblktime(gtx950, kernels[kid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0286245, 0.01431225]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_blk_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now we model the multiple kernel concurrent execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class sm_stat:\n",
    "    def __init__(self, thread=0, reg=0, sharedmem = 0, full=0, batch = 1):\n",
    "        self.thread = thread\n",
    "        self.reg= reg\n",
    "        self.sharedmem = sharedmem\n",
    "        self.full = full\n",
    "        self.batch = batch\n",
    "\n",
    "    def init(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch = 1\n",
    "    \n",
    "    def replenish(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch += 1 # add\n",
    "        \n",
    "    def Rm(self, Kern):\n",
    "        \"\"\"\n",
    "        Remove the kernel block occupied resource by adding them back.\n",
    "        \"\"\"\n",
    "        self.thread += Kern.blockDim\n",
    "        self.reg += Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem += Kern.sharedmem_per_blk\n",
    "\n",
    "    def Allocate_block(self, Kern):\n",
    "        self.thread -= Kern.blockDim\n",
    "        self.reg -= Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem -= Kern.sharedmem_per_blk\n",
    "\n",
    "        \n",
    "def check_sm_resource(current_sm, block_info):\n",
    "    enough_thread = current_sm.thread >= block_info.blockDim\n",
    "    enough_reg = current_sm.reg >= (block_info.reg_per_thread * block_info.blockDim)\n",
    "    enough_sm = current_sm.sharedmem >= block_info.sharedmem_per_blk\n",
    "    \n",
    "    allocate = False\n",
    "    if enough_thread and enough_reg and enough_sm:\n",
    "        allocate = True\n",
    "    \n",
    "    return allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Search_block_start(df_sm_trace, current_kernel_id):\n",
    "    \"\"\"\n",
    "    Read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "    \"\"\"\n",
    "    \n",
    "    #df_active = df_sm_trace.loc[(df_sm_trace['active'] == 1) & (df_sm_trace['kernel_id'] == current_kernel_id)]\n",
    "    df_active = df_sm_trace.loc[df_sm_trace['active'] == 1]\n",
    "    \n",
    "       \n",
    "    if not df_active.empty:\n",
    "        blk2start = df_active['block_start'].max() # find the closest block\n",
    "\n",
    "        df_active_current_kernel = df_active.loc[df_active['kernel_id'] == current_kernel_id]\n",
    "        if not df_active_current_kernel.empty:\n",
    "            blk2start = df_active_current_kernel['block_start'].max()  # find the closest blk for current kernel\n",
    "    \n",
    "        return blk2start\n",
    "    else:\n",
    "        # when, on current sm, all the blocks are done/de-activated\n",
    "        # warning!!!\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modeling the execution and record the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init SM status\n",
    "sm_num = gtx950.sm_num\n",
    "sms = [sm_stat() for i in range(sm_num)]\n",
    "\n",
    "for i in range(sm_num):\n",
    "    sms[i].init(gtx950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a trace table to record all the block trace: using pd dataframe\n",
    "trace_table = pd.DataFrame(columns=['sm_id', 'block_id', 'block_start', 'block_end', 'batch_id', 'kernel_id', 'active'])\n",
    "\n",
    "# have a trace table for each sm\n",
    "sm_trace = [trace_table for x in range(gtx950.sm_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print len(sm_trace)\n",
    "# print sm_trace[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run the 1st kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# kern = kernels[0] # schedule current kernel on the device\n",
    "# kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "# print kernel_blocks\n",
    "# kern_start = kern.start_ms\n",
    "# print kern_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_sm2start(sm_trace_list, kern_start):\n",
    "    sm_num = len(sm_trace_list)\n",
    "    \n",
    "    AfterPrevKern = False\n",
    "    \n",
    "    empSM = 0\n",
    "    # case 1) there are no trace on each sm\n",
    "    for df_sm in sm_trace_list:\n",
    "        if df_sm.empty:\n",
    "            empSM = empSM + 1 # do nothing\n",
    "\n",
    "    if empSM == sm_num:\n",
    "        return 0, AfterPrevKern       \n",
    "    \n",
    "    # case 2） there are traces: \n",
    "    # by the time where the kernel starts, all the blocks are done already, use sm 0\n",
    "    max_t = 0\n",
    "    for df_sm in sm_trace_list:\n",
    "        cur_max = df_sm.block_end.max()\n",
    "        if cur_max > max_t:\n",
    "            max_t = cur_max\n",
    "            \n",
    "    if max_t <= kern_start:\n",
    "        AfterPrevKern = True\n",
    "        return 0, AfterPrevKern\n",
    "    else:\n",
    "        # case 3) : check currently active blocks\n",
    "        df_sm = sm_trace_list[0]\n",
    "        df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "        min_t = df_activeblk.block_end.min()\n",
    "        target_sm = 0\n",
    "        \n",
    "        for i in range(1,sm_num):\n",
    "            df_sm = sm_trace_list[i]\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            sm_blk_min = df_activeblk.block_end.min()\n",
    "            if sm_blk_min < min_t:\n",
    "                min_t = sm_blk_min\n",
    "                target_sm = i\n",
    "                \n",
    "        return target_sm, AfterPrevKern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cke_model(sms_, sm_trace_, kernels_):\n",
    "    # deep copy the input\n",
    "    # we need to return the resource and trace for each sm after modeling\n",
    "    sms = copy.deepcopy(sms_)\n",
    "    sm_trace = copy.deepcopy(sm_trace_)\n",
    "    kernels = copy.deepcopy(kernels_)\n",
    "    \n",
    "    kernel_num = len(kernels)\n",
    "    \n",
    "    # go through each kernel\n",
    "    for i in range(kernel_num):\n",
    "        kern = kernels[i] # schedule current kernel on the device\n",
    "\n",
    "        kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "    #     print kernel_blocks\n",
    "\n",
    "        kern_start = kern.start_ms\n",
    "        print('kern-{}: start {}'.format(i, kern_start))\n",
    "\n",
    "        # 1) find the which sm to start\n",
    "        # 2) compute whether kernel_start happens before previous kernel ends or not\n",
    "        sm2start, AfterPrevKern = find_sm2start(sm_trace, kern_start)\n",
    "        print('sm2start : {}, AfterPrevKern {}'.format(sm2start, AfterPrevKern))\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Run after previous kernel\n",
    "        #---------------------------------------------------------\n",
    "        if AfterPrevKern:\n",
    "            # deactivate all the previous active blocks\n",
    "            myid = 0\n",
    "            for df_sm in sm_trace:\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                for index, row in df_activeblk.iterrows():     # find the row index of active blocks\n",
    "                    sm_trace[myid].loc[index]['active'] = 0    # deactivate \n",
    "                    sms[myid].Rm(kern)                         # free the block resource\n",
    "                    myid = myid + 1\n",
    "\n",
    "    #         if i==1: break\n",
    "\n",
    "\n",
    "        #---------------------------------------------------------\n",
    "        # Continue current kernel\n",
    "        #---------------------------------------------------------\n",
    "        for bid in range(kernel_blocks):\n",
    "            sm_id = (bid + sm2start) % sm_num\n",
    "            print('sm_id {} '.format(sm_id))\n",
    "\n",
    "            to_allocate_another_block = check_sm_resource(sms[sm_id], kern)\n",
    "            print('to_allocate_another_block {}'.format(to_allocate_another_block)) \n",
    "\n",
    "            #----------------------------------\n",
    "            # there is enough resource to host the current block\n",
    "            #----------------------------------\n",
    "            if to_allocate_another_block == True:\n",
    "                sms[sm_id].Allocate_block(kern)  # deduct resources on the current sm\n",
    "\n",
    "                #---------------------------------------\n",
    "                # register the block in the trace table\n",
    "                #---------------------------------------\n",
    "                block_start = None\n",
    "\n",
    "                offset = 0.0\n",
    "                if AfterPrevKern and bid < sm_num:  # Noted: only the 1st block will adjut the kern_start\n",
    "                    offset = kern_start\n",
    "\n",
    "                # if current sm trace table is empty, start from 0\n",
    "                # else find the blocks that will end soon, and retire them\n",
    "                if sm_trace[sm_id].empty:\n",
    "                    block_start = 0\n",
    "                else:\n",
    "                    # read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "                    block_start = Search_block_start(sm_trace[sm_id], i) + offset\n",
    "\n",
    "\n",
    "                block_end = block_start + avg_blk_time_list[i]\n",
    "\n",
    "                print('kern {} : block_start: {}, block_end: {}, block_start {}'.format(i, \n",
    "                                                                block_start, block_end, \n",
    "                                                                Search_block_start(sm_trace[sm_id], i)))\n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "    #             if i==1 and bid == 0: \n",
    "    #                 print('block_start {}, block_end {}, kern_start {}'.format(block_start, block_end, kern_start))\n",
    "    #                 break\n",
    "\n",
    "                # add the current block info to the current sm\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start, # add the kern stat\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "\n",
    "            #-------------------------------------------\n",
    "            # There is no more resources to host the blk, consider SM is full now\n",
    "            # we need to (1) decide how many blks to retire (2) when to start current blk\n",
    "            if to_allocate_another_block == False:\n",
    "                # find out the active blocks on current sm\n",
    "                df_sm = sm_trace[sm_id]\n",
    "                df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "                df_loc = df_activeblk.copy(deep=True)\n",
    "\n",
    "                cur_activeblk_num = df_activeblk.shape[0]\n",
    "\n",
    "\n",
    "                for ii in range(cur_activeblk_num):\n",
    "                    # find out blocks ending soon\n",
    "                    blkend_min = df_loc['block_end'].min()\n",
    "                    df_blk2end = df_loc.loc[df_loc['block_end'] == blkend_min]\n",
    "\n",
    "                    # retire the blocks\n",
    "                    for index, row in df_blk2end.iterrows():\n",
    "                        sm_trace[sm_id].loc[index]['active'] = 0 \n",
    "                        sms[sm_id].Rm(kern) # free the block resource\n",
    "\n",
    "                    # enough to allocate a current block\n",
    "                    if check_sm_resource(sms[sm_id], kern):\n",
    "                        sms[sm_id].Allocate_block(kern)\n",
    "\n",
    "                        block_start = blkend_min # when prev blks end, current block starts\n",
    "                        block_end = block_start + avg_blk_time_list[i]     # add avgblktime for currrent kernel\n",
    "                        break # jump out of the loop\n",
    "                    else:\n",
    "                        # not enough to allocat another block, remove\n",
    "                        df_loc = df_sm.loc[df_sm['active'] == 1]\n",
    "\n",
    "    #             print('kernel {}'.format(i))\n",
    "    #             if i==1 and bid == 8: break\n",
    "\n",
    "                # update the trace table\n",
    "                sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                          'block_id': bid, \n",
    "                                                          'block_start': block_start,\n",
    "                                                          'block_end' : block_end,\n",
    "                                                          'batch_id': sms[sm_id].batch,\n",
    "                                                          'kernel_id': i,\n",
    "                                                          'active': 1}, ignore_index=True)\n",
    "            \n",
    "    # return the updated sm resource and trace table\n",
    "    return sms, sm_trace\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'deepcoyy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ff05b696651c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcke_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-1843c13228d5>\u001b[0m in \u001b[0;36mcke_model\u001b[0;34m(sms_, sm_trace_, kernels_)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msm_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_trace_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mkernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcoyy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mkernel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'deepcoyy'"
     ]
    }
   ],
   "source": [
    "sms, sm_trace = cke_model(sms, sm_trace, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sm_trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sm_trace[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Plot_sm_trace(df_sm):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # color to pick\n",
    "    color_list = ['r', 'k', 'b', 'g', 'c', 'm', 'y', '#cc0000', '#cc6600', 'cc9900',\n",
    "                  '#cc3300', '#cccc00', '#99cc00', '#66cc00', '#00cccc', '#0033cc', \n",
    "                  '#6600cc', '#cc00cc', '#ff99cc', 'ffcc00']\n",
    "    \n",
    "    total_color = len(color_list) \n",
    "    \n",
    "    kern_ids = df_sm['kernel_id'].unique()\n",
    "    \n",
    "    x0_dd = {}\n",
    "    x1_dd = {}\n",
    "    y0_dd = {}\n",
    "    \n",
    "    ylim_max = 0\n",
    "    \n",
    "    for kid in kern_ids:\n",
    "        offset = 0.1 * kid\n",
    "        df_kern = df_sm.loc[df_sm['kernel_id'] == kid] # get the data for current kernel on\n",
    "        df_kern['y_axis'] = pd.Series(np.arange(1,len(df_kern.index)+1) + offset, \n",
    "                                      index=df_kern.index) # adding y_axis label\n",
    "    \n",
    "        x0_dd[kid] = df_kern['block_start']\n",
    "        x1_dd[kid] = df_kern['block_end']\n",
    "        y0_dd[kid] = df_kern['y_axis']\n",
    "\n",
    "        current_ymax = max(df_kern['y_axis']) + 1\n",
    "    \n",
    "        if ylim_max < current_ymax:\n",
    "            ylim_max = current_ymax\n",
    "    \n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, ylim_max])\n",
    "\n",
    "    for kid in kern_ids:\n",
    "        cid = int(kid) % total_color\n",
    "        plt.hlines(y0_dd[kid], x0_dd[kid], x1_dd[kid], lw=2, color=color_list[cid])\n",
    "\n",
    "    \n",
    "                                \n",
    "# #     plt.title('Memory Bound')\n",
    "    plt.xlabel('Time(clocks)')\n",
    "    plt.ylabel('Blocks')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#---------------------\n",
    "# plot\n",
    "#---------------------\n",
    "df_sm = sm_trace[0]\n",
    "\n",
    "Plot_sm_trace(df_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
