{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "    \n",
    "Given the information on gpu and kernel, model the concurrent kernel runtime.\n",
    "\n",
    "Shortcomings:\n",
    "* assume the kernels are in 1D grid\n",
    "* running the same kernels, but should be different in the real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeviceInfo():\n",
    "    def __init__(self, sm_num=0, sharedmem_per_sm=0, reg_per_sm=0, maxthreads_per_sm=0):\n",
    "        self.sm_num = sm_num\n",
    "        self.sharedmem_per_sm = sharedmem_per_sm # bytes\n",
    "        self.reg_per_sm = reg_per_sm\n",
    "        self.maxthreads_per_sm = maxthreads_per_sm\n",
    "        \n",
    "class KernelInfo():\n",
    "    def __init__(self, blockDim=0, gridDim=0, reg_per_thread=0, sharedmem_per_blk=0, runtime_ms = 0):\n",
    "        self.blockDim = blockDim\n",
    "        self.gridDim = gridDim\n",
    "        self.reg_per_thread = reg_per_thread\n",
    "        self.sharedmem_per_blk =  sharedmem_per_blk\n",
    "        self.runtime_ms = runtime_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtx950 = DeviceInfo()\n",
    "gtx950.sm_num = 6\n",
    "gtx950.sharedmem_per_sm = 49152\n",
    "gtx950.reg_per_sm = 65536\n",
    "gtx950.maxthreads_per_sm = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = KernelInfo()\n",
    "kernel.blockDim = 256\n",
    "kernel.gridDim = 90\n",
    "kernel.reg_per_thread = 28\n",
    "kernel.sharedmem_per_blk= 0\n",
    "kernel.runtime_ms = 0.057249"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute average block execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MaxBLK_Per_SM(Gpu, Kern):\n",
    "    \"\"\"\n",
    "    Compute the max blocks on one SM\n",
    "    \"\"\"\n",
    "    warp_size = 32\n",
    "    DeviceLimit = Gpu.maxthreads_per_sm / 32\n",
    "    \n",
    "    blocks_by_sm = DeviceLimit\n",
    "    \n",
    "    if Kern.sharedmem_per_blk > 0:\n",
    "        blocks_by_sm = floor(Gpu.sharedmem_per_sm / float(Kern.sharedmem_per_blk)) # int operation\n",
    "        \n",
    "    blocks_by_reg = floor(Gpu.reg_per_sm / float(Kern.reg_per_thread * Kern.blockDim))\n",
    "    \n",
    "    blocks_by_threads = floor(Gpu.maxthreads_per_sm / float(Kern.blockDim))\n",
    "    \n",
    "    # maxblks_per_sm\n",
    "    return min([blocks_by_sm, blocks_by_reg, blocks_by_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "max_blk_per_sm = MaxBLK_Per_SM(gtx950, kernel)\n",
    "print max_blk_per_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations 2.0\n",
      "avg block execution time (ms) : 0.0286245\n"
     ]
    }
   ],
   "source": [
    "# max blocks that can be launhed on gpu at once time\n",
    "# if there are more blocks, they will wait for the next iteration\n",
    "# each SM starts and finishes at the same time\n",
    "# all the blocks on that SM starts and ends at the same time\n",
    "block_per_iteration = gtx950.sm_num * max_blk_per_sm\n",
    "\n",
    "iterations = ceil(kernel.gridDim / block_per_iteration) # total iterations\n",
    "print 'iterations ' + str(iterations)\n",
    "\n",
    "# divide the kernel runtime by the number of iterations will be the avg block exeuction time for our model\n",
    "avg_blk_time = kernel.runtime_ms / float(iterations)\n",
    "print('avg block execution time (ms) : {}'.format(avg_blk_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we model the multiple kernel concurrent execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sm_stat:\n",
    "    def __init__(self, thread=0, reg=0, sharedmem = 0, full=0, batch = 1):\n",
    "        self.thread = thread\n",
    "        self.reg= reg\n",
    "        self.sharedmem = sharedmem\n",
    "        self.full = full\n",
    "        self.batch = batch\n",
    "\n",
    "    def init(self, gtx950):\n",
    "        self.thread = gtx950.maxthreads_per_sm\n",
    "        self.reg = gtx950.reg_per_sm\n",
    "        self.sharedmem = gtx950.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch = 1\n",
    "    \n",
    "    def replenish(self, gtx950):\n",
    "        self.thread = gtx950.maxthreads_per_sm\n",
    "        self.reg = gtx950.reg_per_sm\n",
    "        self.sharedmem = gtx950.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch += 1 # add\n",
    "        \n",
    "    def allocate_block(self, Kern):\n",
    "        self.thread -= Kern.blockDim\n",
    "        self.reg -= Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem -= Kern.sharedmem_per_blk\n",
    "\n",
    "        \n",
    "def check_sm_resource(current_sm, block_info):\n",
    "    enough_thread = current_sm.thread >= block_info.blockDim\n",
    "    enough_reg = current_sm.reg >= (block_info.reg_per_thread * block_info.blockDim)\n",
    "    enough_sm = current_sm.sharedmem >= block_info.sharedmem_per_blk\n",
    "    \n",
    "    allocate = 0\n",
    "    if enough_thread and enough_reg and enough_sm:\n",
    "        allocate = 1\n",
    "    \n",
    "    return allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init SM status\n",
    "sm_num = gtx950.sm_num\n",
    "sms = [sm_stat() for i in range(sm_num)]\n",
    "\n",
    "for i in range(sm_num):\n",
    "    sms[i].init(gtx950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "90\n",
      "28\n",
      "0\n",
      "0.057249\n"
     ]
    }
   ],
   "source": [
    "print kernel.blockDim\n",
    "print kernel.gridDim\n",
    "print kernel.reg_per_thread\n",
    "print kernel.sharedmem_per_blk\n",
    "print kernel.runtime_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a trace table to record all the block trace: using pd dataframe\n",
    "trace_table = pd.DataFrame(columns=['sm_id', 'block_id', 'block_start', 'block_end', 'batch_id', 'kernel_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simulate kernel number\n",
    "kernel_num = 2\n",
    "\n",
    "# note, we are running two identical one, but we can change that\n",
    "kernels = [kernel for i in range(kernel_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "print kernels[0].blockDim\n",
    "print kernels[1].blockDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "sm2start = 0\n",
    "\n",
    "for i in range(kernel_num):\n",
    "    kern = kernels[i] # schedule current kernel on the device\n",
    "    kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "    \n",
    "    last_block_on_sm = 0\n",
    "    \n",
    "    #print sm2start\n",
    "    \n",
    "    for bid in range(kernel_blocks):\n",
    "        sm_id = (bid + sm2start) % sm_num\n",
    "            \n",
    "        # check whether current sm has enough resources to host the block\n",
    "        to_allocate_another_block = check_sm_resource(sms[sm_id], kernel)\n",
    "\n",
    "        if to_allocate_another_block == 1:\n",
    "            sms[sm_id].allocate_block(kernel)\n",
    "        else:\n",
    "            # consider it full, update the resources, and register in the trace table\n",
    "            sms[sm_id].replenish(gtx950)\n",
    "            sms[sm_id].allocate_block(kernel)\n",
    "            \n",
    "        # register the block in the trace table\n",
    "        # note: avg blk time for current kernel\n",
    "        block_end = sms[sm_id].batch * avg_blk_time\n",
    "        block_start = block_end - avg_blk_time\n",
    "        trace_table = trace_table.append({'sm_id': sm_id, \n",
    "                                          'block_id': bid, \n",
    "                                          'block_start': block_start,\n",
    "                                          'block_end' : block_end,\n",
    "                                          'batch_id': sms[sm_id].batch,\n",
    "                                          'kernel_id': i}, ignore_index=True)\n",
    "        last_block_on_sm = sm_id\n",
    "        \n",
    "    # end of running previous kernel blocks\n",
    "    sm2start = last_block_on_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_plot_cke(df_s1, df_s2):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df_s1['y_axis'] = pd.Series(np.arange(1,len(df_s1.index)+1), \n",
    "                                 index=df_s1.index)\n",
    "    \n",
    "    df_s2['y_axis'] = pd.Series(np.arange(1,len(df_s2.index)+1) + 0.1, \n",
    "                                 index=df_s2.index)\n",
    "                                     \n",
    "    x0=df_s1['block_start']\n",
    "    x1=df_s1['block_end']\n",
    "    y0=df_s1['y_axis']\n",
    "                                \n",
    "    x0_=df_s2['block_start']\n",
    "    x1_=df_s2['block_end']\n",
    "    y0_=df_s2['y_axis']\n",
    "\n",
    "    ylim_max = max(df_s1['y_axis']) + 1\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, ylim_max])\n",
    "\n",
    "    plt.hlines(y0,x0,x1, lw=2, color='r')\n",
    "    plt.hlines(y0_,x0_,x1_, lw=2, color='k')\n",
    "                                \n",
    "#     plt.title('Memory Bound')\n",
    "    plt.xlabel('Time(clocks)')\n",
    "    plt.ylabel('Blocks')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the sm-0 data\n",
    "df_sm = trace_table.loc[trace_table['sm_id'] == 0]\n",
    "\n",
    "df_kern0 = df_sm.loc[df_sm['kernel_id'] == 0]\n",
    "df_kern1 = df_sm.loc[df_sm['kernel_id'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE/ZJREFUeJzt3X20ZXV93/H3hxmJgiiQmRgDTMEkQIkrCN4YIjZBsAkR\nK02bVlmxUWsyKzY1aGJR81BNWrpYlRhNNDZTQTRSUhcQY02iUBXRRpEBQR7ViA8ZApkhhPgMKt/+\ncfYkZ+6aPfc83H32OWfer7X2umfvs/f+/X733nM++/G3U1VIkrQ3B/RdAUnS/DIkJEmtDAlJUitD\nQpLUypCQJLUyJCRJrToLiSQXJ9mZ5NZV01+S5M4ktyX5712VL0maXpd7EpcAZw5PSPJ04GzgxKr6\nAeDCDsuXJE2ps5CoqmuB+1dNfjFwQVU92Myzs6vyJUnT2zjj8o4F/lmS84FvAC+vquv3NmOSrcBW\ngIMPPvjJxx9//OxqKUlL4IYbbrivqjZPs45Zh8RG4HDgFOCHgHcmeULtpW+QqtoGbANYWVmp7du3\nz7SikrToknxh2nXM+uqmHcCVNfBx4GFg04zrIEka0axD4l3A0wGSHAscCNw34zpIkkbU2eGmJJcB\npwGbkuwAXg1cDFzcXBb7EPD8vR1qkiTNh85CoqrOaXnreV2VKUlaX95xLUlqZUhIkloZEpKkVoaE\nJKmVISFJamVISJJazbpbDkn7sSR9V2Hh9H0rmSGhPfkhHo/3gmrJGRKSZqbvrWKNz5DQnvwQSxri\niWtJUitDQpLUypCQJLUyJCRJrQwJSVIrQ0KS1MqQkCS1MiQkSa06C4kkFyfZ2TzPevV7v5Kkkmzq\nqnxJ0vS6vOP6EuCNwNuHJyY5Cvhx4Isdli1pDtnB3/j67sqksz2JqroWuH8vb/0OcB5g/w+SNOdm\n2ndTkrOBu6vqZrco5pR/l/HY19VY+t4q1vhmFhJJDgJ+lcGhplHm3wpsBdiyZUuHNZMktZnlnsT3\nAscAu/cijgRuTPKUqrp39cxVtQ3YBrCysuLmx6y4pSdpyMxCoqpuAb5r93iSzwMrVXXfrOogSRpP\nl5fAXgZ8FDguyY4kL+qqLElSNzrbk6iqc9Z4/+iuypYkrQ/vuJYktTIkJEmtDAlJUitDQpLUypCQ\nJLUyJCRJrWbad5Ok/Zt9to2v7/6uDAntyQ/xeOzGREvOkJA0M31vFWt8hoT25IdY0hBPXEuSWhkS\nkqRWhoQkqZUhIUlqZUhIkloZEpKkVoaEJKmVISFJamVISJJadXbHdZKLgWcBO6vqic201wL/AngI\n+Czwwqp6oKs6SJovdvA3vr67MulyT+IS4MxV064GnlhVPwh8GnhVh+VLkqbU2Z5EVV2b5OhV064a\nGv0Y8NNdla8JuaU3Hvu6GkvfW8UaX5/nJP498OdtbybZmmR7ku27du2aYbUkSbv10gtskl8DvgVc\n2jZPVW0DtgGsrKy4+TErbulJGjLzkEjyAgYntM8o9z0laa7NNCSSnAmcB/xYVX1tlmVLksbX2TmJ\nJJcBHwWOS7IjyYuANwKHAFcnuSnJ/+iqfEnS9Lq8uumcvUy+qKvyJEnrzzuuJUmtDAlJUitDQpLU\nypCQJLUyJCRJrXq541rS/sleYMfX9z3HhoT25Id4PHYaoCVnSEiamb63ijU+Q0J78kMsaYgnriVJ\nrQwJSVIrQ0KS1MqQkCS1MiQkSa0MCUlSK0NCktTKkJAktTIkJEmtunzG9cVJdia5dWja4UmuTvKZ\n5udhXZUvSZpel3sSlwBnrpr2SuD9VfX9wPubcUn7iSQOYw5966zvpqq6NsnRqyafDZzWvH4bcA3w\niq7qoAnMwT/lQrGvKy25WXfw97iquqd5fS/wuLYZk2wFtgJs2bJlBlWT1DV7gV08vfUCW1WVpPU/\npqq2AdsAVlZW/M+aFT/EkobM+uqmv0nyeIDm584Zly9JGsOsQ+LdwPOb188H/mTG5UuSxtDlJbCX\nAR8FjkuyI8mLgAuAf57kM8AzmnFJ0pzq8uqmc1reOqOrMiVJ68s7riVJrQwJSVIrQ0KS1MqQkCS1\nMiQkSa16u+NaWgbz0AHbIrFbjsVjSGhPfulJGmJISFNwy1jLbqRzEkn+TZJDmte/nuTKJCd3WzX1\nosphnEFacqOeuP6Nqvpykqcx6E7jIuDN3VVLkjQPRg2Jbzc/zwK2VdWfAgd2UyVJ0rwYNSTuTvIH\nwHOAP0vyHWMsK0laUKN+0f9b4H3AT1TVA8DhwH/qrFaSpLkwakicU1VXVtVnAJpHkJ7eXbUkSfNg\n1Etg/3WSb1TVpQBJ3gQ8srtqSZLmwcghAbw7ycPAmcADVfWi7qolSZoH+wyJJIcPjf4c8C7g/wG/\nmeTwqrq/y8pJkvq11p7EDUABGfp5VjMU8IROaydJ6tU+Q6Kqjumi0CQvY7BnUsAtwAur6htdlCVJ\nmtyo3XL8YpJDh8YPS/IfJikwyRHALwErVfVEYAPw3EnWJfUticMYgxbPqJfA/nxzfwQAVfV3wM9P\nUe5G4FFJNgIHAX89xbr2LXEYZ5CkIaNe3bQhSarp8jLJBibslqOq7k5yIfBF4OvAVVV11er5kmwF\ntgJs2bJlkqKkztkLrJbdqHsS7wX+d5IzkpwBXNZMG1uSw4CzgWOA7wEOTvK81fNV1baqWqmqlc2b\nN09S1O4VOdirqaQJjRoSrwA+CLy4Gd4PnDdhmc8APldVu6rqm8CVwFMnXJckqUMjHW6qqoeTXAR8\nhMEVSZ+qqm+vsVibLwKnJDmIweGmM4DtE65LktShkUIiyWnA24DPM7hX4qgkz6+qa8ctsKquS3I5\ncCPwLeATwLZx1yNJ6t6oJ65/G/jxqvoUQJJjGZyXePIkhVbVq4FXT7KsJGl2Rj0n8YjdAQFQVZ8G\nHtFNlSRJ82LUPYntSd4CvKMZ/xk8jyBJS2/UkHgx8IsM7pQG+DDw+53USJI0N0a9uulB4HXNIEna\nT6zVVfgtDC553auq+sF1r5EkaW6stSfxrJnUQlpQdlo3HrsxWTxrdRX+hdXTkmwC/rb8a0vS0lvr\ncNMpwAXA/cB/Af4Q2AQckORnq2qi/ptmyi298Zj9Y3FbScturcNNbwR+FXgs8AHgJ6vqY0mOZ4pO\n/iRJi2GtkNi4uxvvJL9VVR8DqKo7F+ZYrFt6kjSxte64fnjo9ddXvee3ryQtubX2JE5M8iUGnfo9\nqnlNM/7ITmsmSerdWlc3bZhVRSRJ82fUDv4kSfshQ0KS1MqQkCS1MiQkSa0MCUlSq15CIsmhSS5P\ncmeSO5L8SB/1kCTt26gPHVpvbwDeW1U/neRA4KCe6iFNZWF6HpgT9nW1eGYeEkkeC/wo8AKAqnoI\neKjDAjtb9VLyQyxpSB97EscAu4C3JjkRuAE4t6q+OjxTkq3AVoAtW7bMvJLSKNwy1rLr45zERuBk\n4M1VdRLwVeCVq2eqqm1VtVJVK5s3b568tCqHcQZJGtJHSOwAdlTVdc345QxCQ5I0Z2YeElV1L/BX\nSY5rJp0B3D7rekiS1tbX1U0vAS5trmy6C3hhT/WQJO1DLyFRVTcBK32ULUkanXdcS5JaGRKSpFaG\nhCSplSEhSWplSEiSWvV1Cay0FOzgbzx2Y7J43JOQJLVa/j0Jt/TG45beWNwy1rJzT0KS1Gr59yTc\n0pOkibknIUlqZUhIkloZEpKkVoaEJKmVISFJamVISJJaGRKSpFaGhCSpVW8hkWRDkk8keU9fdZAk\n7Vufd1yfC9wBPKbHOkhTsRfY8djX1eLpJSSSHAmcBZwP/HLHhXW6+qXjh1jSkL72JF4PnAcc0jZD\nkq3AVoAtW7bMqFrSeNwy1rKb+TmJJM8CdlbVDfuar6q2VdVKVa1s3rx58gKrHMYZJGlIHyeuTwWe\nneTzwB8Bpyd5Rw/1kCStYeYhUVWvqqojq+po4LnAB6rqebOuhyRpbd4nIUlq1etDh6rqGuCaPusg\nSWrnnoQkqZUhIUlqZUhIkloZEpKkVoaEJKmVISFJatXrJbDSorMX2PHY19XiWf6Q8EM8Hj/EkoYs\nf0hIHXLLWMtu+UPCD7EkTcwT15KkVoaEJKmVISFJamVISJJaGRKSpFaGhCSplSEhSWplSEiSWs08\nJJIcleSDSW5PcluSc2ddB0nSaPq44/pbwK9U1Y1JDgFuSHJ1Vd3eQ12kqdjB33jsxmTxzHxPoqru\nqaobm9dfBu4Ajph1PSRJa+u176YkRwMnAdd1WEhnq15KbumNxS1jLbveTlwneTRwBfDSqvrSXt7f\nmmR7ku27du2afQUlSf3sSSR5BIOAuLSqrtzbPFW1DdgGsLKyMvnmmlt6kjSxPq5uCnARcEdVvW7W\n5UuSRtfH4aZTgX8HnJ7kpmZ4Zg/1kCStYeaHm6rqI4BnkyVpAXjHtSSplSEhSWplSEiSWhkSkqRW\nhoQkqZUhIUlq1WvfTZo/9mo6Hvtu0rJb/pDwS0+SJrb8IaGxuGUsadjyh4RfepI0MU9cS5JaGRKS\npFaGhCSplSEhSWplSEiSWhkSkqRWhoQkqZUhIUlqZUhIklr1EhJJzkzyqSR/meSVfdRBkrS2mYdE\nkg3Am4CfBE4AzklywqzrIUlaWx97Ek8B/rKq7qqqh4A/As7uoR6SpDX00cHfEcBfDY3vAH549UxJ\ntgJbm9GvJPnUhOVtAu6bcNl5ZZsWxzK2yzYthk3AP5l2JXPbC2xVbQO2TbueJNuramUdqjQ3bNPi\nWMZ22abF0LTp6GnX08fhpruBo4bGj2ymSZLmTB8hcT3w/UmOSXIg8Fzg3T3UQ5K0hpkfbqqqbyX5\nj8D7gA3AxVV1W4dFTn3Iag7ZpsWxjO2yTYthXdoUH1cpSWrjHdeSpFaGhCSp1UKHxFrde2Tgd5v3\nP5nk5FGX7cukbUpyVJIPJrk9yW1Jzp197fdumr9T8/6GJJ9I8p7Z1XrfpvzfOzTJ5UnuTHJHkh+Z\nbe33bso2vaz5v7s1yWVJHjnb2u/dCG06PslHkzyY5OXjLNunSds10fdEVS3kwOCk92eBJwAHAjcD\nJ6ya55nAnwMBTgGuG3XZBWzT44GTm9eHAJ9e9DYNvf/LwP8C3tN3e9ajTcDbgJ9rXh8IHLrIbWJw\ng+zngEc14+8EXrAgbfou4IeA84GXj7PsgrZr7O+JRd6TGKV7j7OBt9fAx4BDkzx+xGX7MHGbquqe\nqroRoKq+DNzB4MPbt2n+TiQ5EjgLeMssK72GiduU5LHAjwIXAVTVQ1X1wCwr32KqvxODKyUflWQj\ncBDw17Oq+D6s2aaq2llV1wPfHHfZHk3crkm+JxY5JPbWvcfqxrbNM8qyfZimTf8gydHAScB1617D\n8U3bptcD5wEPd1XBCUzTpmOAXcBbm0Nob0lycJeVHdHEbaqqu4ELgS8C9wB/X1VXdVjXUU3zOZ/X\n7whYp7qN+j2xyCGhvUjyaOAK4KVV9aW+6zONJM8CdlbVDX3XZR1tBE4G3lxVJwFfBebqePe4khzG\nYEv2GOB7gIOTPK/fWmlfxvmeWOSQGKV7j7Z55rVrkGnaRJJHMPjDX1pVV3ZYz3FM06ZTgWcn+TyD\nXerTk7yju6qObJo27QB2VNXurbfLGYRG36Zp0zOAz1XVrqr6JnAl8NQO6zqqaT7n8/odAVPWbezv\nib5Pwkxx8mYjcBeDrZfdJ29+YNU8Z7HnibaPj7rsArYpwNuB1/fdjvVq06p5TmN+TlxP1Sbgw8Bx\nzevXAK9d5DYx6MX5NgbnIsLgxPxLFqFNQ/O+hj1P8M7ld8Q6tGvs74neGzzlL+uZDM7Ofxb4tWba\nLwC/MPQLeVPz/i3Ayr6WnYdh0jYBTwMK+CRwUzM8s+/2TPt3GlrHacxJSKzD/96TgO3N3+pdwGF9\nt2cd2vSbwJ3ArcAfAt/Rd3tGbNN3M9i7+xLwQPP6MW3Lzsswabsm+Z6wWw5JUqtFPichSeqYISFJ\namVISJJaGRKSpFaGhCSplSGhhZfkO5Pc1Az3Jrl7aPwv1rGcf5nkP68xz1cmXPc1SVZGnPfCJKdP\nUo40rpk/vlRab1X1twzuPSDJa4CvVNWFHRR1HvDsDtY7rt8D/ifwgb4rouXnnoSW2u4t+ySnJflQ\nkj9JcleSC5L8TJKPJ7klyfc2821OckWS65vh1Gb6scCDVXVfM/64JH+c5OZmeOqqcpPktc3zFW5J\n8pyh917RTLs5yQWrljsgySVJ/msGz9G4ZGgdLwOoqi8A35nku7v83UngnoT2LycC/xS4n0G3Bm+p\nqqc0D155CfBS4A3A71TVR5JsAd7XLHMqcOPQun4X+FBV/VSSDcCjV5X1rxjs3ZwIbAKuT3JtM+1s\n4Ier6mtJDh9aZiNwKXBrVZ2f5MkMell9IgweVjQ0741Nna6Y7lci7Zshof3J9VV1D0CSzwK7u7O+\nBXh68/oZwAlJdi/zmKbHzMcz6OJ7t9OBnwWoqm8Df7+qrKcBlzXv/U2SDzF4CMyPAW+tqq81y94/\ntMwfAO+sqvOb8buAJyT5PeBPh+oLsJNBj6tSpzzcpP3Jg0OvHx4af5h/3GA6ADilqp7UDEdU1VeA\nrwNdP5LzL4Cn7370Z1X9HYM9kWsY9Msz/OClRzZ1kjplSEh7uorBoScAkjypeXkH8H1D870feHEz\nz4bmiXPDPgw8p3lvM4On0X0cuBp4YZKDmmWHDzddBPwZ8M4kG5NsAg6oqiuAX2fPLsWPZdCZntQp\nQ0La0y8BK0k+meR2BlvwANcCJ+Ufj0Ody2Cr/xbgBuCEVev5YwY9bd7M4Cqk86rq3qp6L/BuYHuS\nm4CXDy9UVa8DPsGgJ9UjgGua+d4BvAr+4XkA38egJ1mpU/YCK40oyRuA/1NV/7fnevwUg4fZ/0af\n9dD+wT0JaXT/jcGDdfq2Efjtviuh/YN7EpKkVu5JSJJaGRKSpFaGhCSplSEhSWplSEiSWv1/Qel7\nJRFA5bUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22ce32df10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_plot_cke(df_kern0, df_kern1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
