{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Motivation:\n",
    "    \n",
    "Given the information on gpu and kernel, model the concurrent kernel runtime.\n",
    "\n",
    "**Shortcomings**:\n",
    "* assume the kernels are in 1D grid\n",
    "* the input for the model should be a list of all the kernels in N cuda streams. Right now, we assume the two kernels are from two different cuda streams, which seems confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**New**:\n",
    "\n",
    "* the coming kernel starting time can be adjustable\n",
    "* warp modeling inside function, use global data trace table to keep track each trace\n",
    "* instead of running loop, we unroll it. in this way, the coming kernel can be (flexibly) added to the sm trace.\n",
    "* change cke_model() to run_gpu_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy  # deep copy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DeviceInfo():\n",
    "    def __init__(self, sm_num=0, sharedmem_per_sm=0, reg_per_sm=0, maxthreads_per_sm=0):\n",
    "        self.sm_num = sm_num\n",
    "        self.sharedmem_per_sm = sharedmem_per_sm # bytes\n",
    "        self.reg_per_sm = reg_per_sm\n",
    "        self.maxthreads_per_sm = maxthreads_per_sm\n",
    "        \n",
    "class KernelInfo():\n",
    "    def __init__(self, blockDim=0, gridDim=0, reg_per_thread=0, sharedmem_per_blk=0, runtime_ms = 0, start = 0):\n",
    "        self.blockDim = blockDim\n",
    "        self.gridDim = gridDim\n",
    "        self.reg_per_thread = reg_per_thread\n",
    "        self.sharedmem_per_blk =  sharedmem_per_blk\n",
    "        self.runtime_ms = runtime_ms\n",
    "        self.start_ms = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MaxBLK_Per_SM(Gpu, Kern):\n",
    "    \"\"\"\n",
    "    Compute the max blocks on one SM\n",
    "    \"\"\"\n",
    "    warp_size = 32\n",
    "    DeviceLimit = Gpu.maxthreads_per_sm / 32\n",
    "    \n",
    "    blocks_by_sm = DeviceLimit\n",
    "    \n",
    "    if Kern.sharedmem_per_blk > 0:\n",
    "        blocks_by_sm = floor(Gpu.sharedmem_per_sm / float(Kern.sharedmem_per_blk)) # int operation\n",
    "        \n",
    "    blocks_by_reg = floor(Gpu.reg_per_sm / float(Kern.reg_per_thread * Kern.blockDim))\n",
    "    \n",
    "    blocks_by_threads = floor(Gpu.maxthreads_per_sm / float(Kern.blockDim))\n",
    "    \n",
    "    # maxblks_per_sm\n",
    "    return min([blocks_by_sm, blocks_by_reg, blocks_by_threads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_avgblktime(Gpu, kernel):\n",
    "    max_blk_per_sm = MaxBLK_Per_SM(Gpu, kernel)\n",
    "    print('max blk per sm = {}'.format(max_blk_per_sm))\n",
    "    \n",
    "    block_per_iteration = Gpu.sm_num * max_blk_per_sm\n",
    "    iterations = ceil(kernel.gridDim / block_per_iteration) # total iterations\n",
    "    avg_blk_time = kernel.runtime_ms / float(iterations)\n",
    "    \n",
    "    return avg_blk_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gtx950 = DeviceInfo()\n",
    "gtx950.sm_num = 2\n",
    "gtx950.sharedmem_per_sm = 49152\n",
    "gtx950.reg_per_sm = 65536\n",
    "gtx950.maxthreads_per_sm = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup kernel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simulate kernel number\n",
    "kernel_num = 2\n",
    "\n",
    "kernels = [KernelInfo() for i in range(kernel_num)]\n",
    "\n",
    "kernels[0].blockDim = 512\n",
    "kernels[0].gridDim = 10\n",
    "kernels[0].reg_per_thread = 28\n",
    "kernels[0].sharedmem_per_blk= 0\n",
    "kernels[0].runtime_ms = 0.057249\n",
    "kernels[0].start_ms = 0.0                                      # run the kernel at the beginning  \n",
    "\n",
    "kernels[1].blockDim = 512\n",
    "kernels[1].gridDim = 10\n",
    "kernels[1].reg_per_thread = 28\n",
    "kernels[1].sharedmem_per_blk= 0\n",
    "kernels[1].runtime_ms = 0.057249 * 0.5   # assume half runtime\n",
    "\n",
    "# kernels[1].start_ms = kernels[0].start_ms + kernels[0].runtime_ms * 0.5  # run the kernel after kernel 0\n",
    "#kernels[1].start_ms = kernels[0].start_ms + kernels[0].runtime_ms * 0.7  # run the kernel after kernel 0\n",
    "kernels[1].start_ms = kernels[0].start_ms + kernels[0].runtime_ms  # run the kernel after kernel 0\n",
    "\n",
    "\n",
    "# kernels[2].blockDim = 512\n",
    "# kernels[2].gridDim = 10\n",
    "# kernels[2].reg_per_thread = 28\n",
    "# kernels[2].sharedmem_per_blk= 0\n",
    "# kernels[2].runtime_ms = 0.057249 * 2  # assume x2 runtime\n",
    "# kernels[1].start_ms = kernels[1].start_ms + kernels[1].runtime_ms    # run after kernel 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### compute average block execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max blk per sm = 4.0\n",
      "max blk per sm = 4.0\n"
     ]
    }
   ],
   "source": [
    "avg_blk_time_list = []\n",
    "\n",
    "for kid in range(kernel_num):\n",
    "    avg_blk_time_list.append(compute_avgblktime(gtx950, kernels[kid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0286245, 0.01431225]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_blk_time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now we model the multiple kernel concurrent execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class sm_stat:\n",
    "    def __init__(self, thread=0, reg=0, sharedmem = 0, full=0, batch = 1):\n",
    "        self.thread = thread\n",
    "        self.reg= reg\n",
    "        self.sharedmem = sharedmem\n",
    "        self.full = full\n",
    "        self.batch = batch\n",
    "\n",
    "    def init(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch = 1\n",
    "    \n",
    "    def replenish(self, Gpu):\n",
    "        self.thread = Gpu.maxthreads_per_sm\n",
    "        self.reg = Gpu.reg_per_sm\n",
    "        self.sharedmem = Gpu.sharedmem_per_sm\n",
    "        self.full = 0 \n",
    "        self.batch += 1 # add\n",
    "        \n",
    "    def Rm(self, Kern):\n",
    "        \"\"\"\n",
    "        Remove the kernel block occupied resource by adding them back.\n",
    "        \"\"\"\n",
    "        self.thread += Kern.blockDim\n",
    "        self.reg += Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem += Kern.sharedmem_per_blk\n",
    "\n",
    "    def Allocate_block(self, Kern):\n",
    "        self.thread -= Kern.blockDim\n",
    "        self.reg -= Kern.reg_per_thread * Kern.blockDim\n",
    "        self.sharedmem -= Kern.sharedmem_per_blk\n",
    "\n",
    "        \n",
    "def check_sm_resource(current_sm, block_info):\n",
    "    enough_thread = current_sm.thread >= block_info.blockDim\n",
    "    enough_reg = current_sm.reg >= (block_info.reg_per_thread * block_info.blockDim)\n",
    "    enough_sm = current_sm.sharedmem >= block_info.sharedmem_per_blk\n",
    "    \n",
    "    allocate = False\n",
    "    if enough_thread and enough_reg and enough_sm:\n",
    "        allocate = True\n",
    "    \n",
    "    return allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Search_block_start(df_sm_trace, current_kernel_id):\n",
    "    \"\"\"\n",
    "    Read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "    \"\"\"\n",
    "    \n",
    "    #df_active = df_sm_trace.loc[(df_sm_trace['active'] == 1) & (df_sm_trace['kernel_id'] == current_kernel_id)]\n",
    "    df_active = df_sm_trace.loc[df_sm_trace['active'] == 1]\n",
    "    \n",
    "       \n",
    "    if not df_active.empty:\n",
    "        blk2start = df_active['block_start'].max() # find the closest block\n",
    "\n",
    "        df_active_current_kernel = df_active.loc[df_active['kernel_id'] == current_kernel_id]\n",
    "        if not df_active_current_kernel.empty:\n",
    "            blk2start = df_active_current_kernel['block_start'].max()  # find the closest blk for current kernel\n",
    "    \n",
    "        return blk2start\n",
    "    else:\n",
    "        # when, on current sm, all the blocks are done/de-activated\n",
    "        # warning!!!\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modeling the execution and record the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init SM status\n",
    "sm_num = gtx950.sm_num\n",
    "sms = [sm_stat() for i in range(sm_num)]\n",
    "\n",
    "for i in range(sm_num):\n",
    "    sms[i].init(gtx950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a trace table to record all the block trace: using pd dataframe\n",
    "trace_table = pd.DataFrame(columns=['sm_id', 'block_id', 'block_start', 'block_end', 'batch_id', 'kernel_id', 'active'])\n",
    "\n",
    "# have a trace table for each sm\n",
    "sm_trace = [trace_table for x in range(gtx950.sm_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print len(sm_trace)\n",
    "# print sm_trace[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run the 1st kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_sm2start(sm_trace_list, kern_start):\n",
    "    sm_num = len(sm_trace_list)\n",
    "    \n",
    "    AfterPrevKern = False\n",
    "    \n",
    "    empSM = 0\n",
    "    # case 1) there are no trace on each sm\n",
    "    for df_sm in sm_trace_list:\n",
    "        if df_sm.empty:\n",
    "            empSM = empSM + 1 # do nothing\n",
    "\n",
    "    if empSM == sm_num:\n",
    "        return 0, AfterPrevKern       \n",
    "    \n",
    "    # case 2） there are traces: \n",
    "    # by the time where the kernel starts, all the blocks are done already, use sm 0\n",
    "    max_t = 0\n",
    "    for df_sm in sm_trace_list:\n",
    "        cur_max = df_sm.block_end.max()\n",
    "        if cur_max > max_t:\n",
    "            max_t = cur_max\n",
    "            \n",
    "    if max_t <= kern_start:\n",
    "        AfterPrevKern = True\n",
    "        return 0, AfterPrevKern\n",
    "    else:\n",
    "        # case 3) : check currently active blocks\n",
    "        df_sm = sm_trace_list[0]\n",
    "        df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "        min_t = df_activeblk.block_end.min()\n",
    "        target_sm = 0\n",
    "        \n",
    "        for i in range(1,sm_num):\n",
    "            df_sm = sm_trace_list[i]\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            sm_blk_min = df_activeblk.block_end.min()\n",
    "            if sm_blk_min < min_t:\n",
    "                min_t = sm_blk_min\n",
    "                target_sm = i\n",
    "                \n",
    "        return target_sm, AfterPrevKern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_gpu_kernel(sms_, sm_trace_, kern, kern_id):\n",
    "    # deep copy the input\n",
    "    # we need to return the resource and trace for each sm after modeling\n",
    "    sms = copy.deepcopy(sms_)\n",
    "    sm_trace = copy.deepcopy(sm_trace_)\n",
    "    #kernel = copy.deepcopy(kernel)\n",
    "    \n",
    "    sm_num = len(sm_trace_)\n",
    "\n",
    "    # schedule current kernel on the device\n",
    "\n",
    "    kernel_blocks = int(kern.gridDim) # total block for current kern\n",
    "    # print kernel_blocks\n",
    "\n",
    "    kern_start = kern.start_ms\n",
    "    print('\\n---------------\\nkern-{}: start {}'.format(kern_id, kern_start))\n",
    "\n",
    "    # 1) find the which sm to start\n",
    "    # 2) compute whether kernel_start happens before previous kernel ends or not\n",
    "    sm2start, AfterPrevKern = find_sm2start(sm_trace, kern_start)\n",
    "    print('sm2start : {}, AfterPrevKern {}'.format(sm2start, AfterPrevKern))\n",
    "\n",
    "    #---------------------------------------------------------\n",
    "    # Run after previous kernel\n",
    "    #---------------------------------------------------------\n",
    "    if AfterPrevKern:\n",
    "        # deactivate all the previous active blocks\n",
    "        myid = 0\n",
    "        for df_sm in sm_trace:\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            for index, row in df_activeblk.iterrows():     # find the row index of active blocks\n",
    "                sm_trace[myid].loc[index]['active'] = 0    # deactivate \n",
    "                sms[myid].Rm(kern)                         # free the block resource\n",
    "                myid = myid + 1\n",
    "\n",
    "    # if i==1: break\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------\n",
    "    # Continue current kernel\n",
    "    #---------------------------------------------------------\n",
    "    for bid in range(kernel_blocks):\n",
    "        sm_id = (bid + sm2start) % sm_num\n",
    "        print('sm_id {} '.format(sm_id))\n",
    "\n",
    "        to_allocate_another_block = check_sm_resource(sms[sm_id], kern)\n",
    "        print('to_allocate_another_block {}'.format(to_allocate_another_block)) \n",
    "\n",
    "        #----------------------------------\n",
    "        # there is enough resource to host the current block\n",
    "        #----------------------------------\n",
    "        if to_allocate_another_block == True:\n",
    "            sms[sm_id].Allocate_block(kern)  # deduct resources on the current sm\n",
    "\n",
    "            #---------------------------------------\n",
    "            # register the block in the trace table\n",
    "            #---------------------------------------\n",
    "            block_start = None\n",
    "\n",
    "            offset = 0.0\n",
    "            if AfterPrevKern and bid < sm_num:  # Noted: only the 1st block will adjut the kern_start\n",
    "                offset = kern_start\n",
    "\n",
    "            # if current sm trace table is empty, start from 0\n",
    "            # else find the blocks that will end soon, and retire them\n",
    "            if sm_trace[sm_id].empty:\n",
    "                block_start = 0\n",
    "            else:\n",
    "                # read the sm_trace table, find out all the active blocks on current sm, look for the earliest start\n",
    "                block_start = Search_block_start(sm_trace[sm_id], kern_id) + offset\n",
    "\n",
    "\n",
    "            block_end = block_start + avg_blk_time_list[kern_id]\n",
    "\n",
    "            print('kern {} : block_start: {}, block_end: {}, block_start {}'.format(kern_id, \n",
    "                                                            block_start, block_end, \n",
    "                                                            Search_block_start(sm_trace[sm_id], kern_id)))\n",
    "#             if i==1 and bid == 8: break\n",
    "\n",
    "#             if i==1 and bid == 0: \n",
    "#                 print('block_start {}, block_end {}, kern_start {}'.format(block_start, block_end, kern_start))\n",
    "#                 break\n",
    "\n",
    "            # add the current block info to the current sm\n",
    "            sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                      'block_id': bid, \n",
    "                                                      'block_start': block_start, # add the kern stat\n",
    "                                                      'block_end' : block_end,\n",
    "                                                      'batch_id': sms[sm_id].batch,\n",
    "                                                      'kernel_id': kern_id,\n",
    "                                                      'active': 1}, ignore_index=True)\n",
    "\n",
    "        #-------------------------------------------\n",
    "        # There is no more resources to host the blk, consider SM is full now\n",
    "        # we need to (1) decide how many blks to retire (2) when to start current blk\n",
    "        if to_allocate_another_block == False:\n",
    "            # find out the active blocks on current sm\n",
    "            df_sm = sm_trace[sm_id]\n",
    "            df_activeblk = df_sm.loc[df_sm['active'] == 1]\n",
    "            df_loc = df_activeblk.copy(deep=True)\n",
    "\n",
    "            cur_activeblk_num = df_activeblk.shape[0]\n",
    "\n",
    "\n",
    "            for ii in range(cur_activeblk_num):\n",
    "                # find out blocks ending soon\n",
    "                blkend_min = df_loc['block_end'].min()\n",
    "                df_blk2end = df_loc.loc[df_loc['block_end'] == blkend_min]\n",
    "\n",
    "                # retire the blocks\n",
    "                for index, row in df_blk2end.iterrows():\n",
    "                    sm_trace[sm_id].loc[index]['active'] = 0 \n",
    "                    sms[sm_id].Rm(kern) # free the block resource\n",
    "\n",
    "                # enough to allocate a current block\n",
    "                if check_sm_resource(sms[sm_id], kern):\n",
    "                    sms[sm_id].Allocate_block(kern)\n",
    "\n",
    "                    block_start = blkend_min # when prev blks end, current block starts\n",
    "                    block_end = block_start + avg_blk_time_list[kern_id]     # add avgblktime for currrent kernel\n",
    "                    break # jump out of the loop\n",
    "                else:\n",
    "                    # not enough to allocat another block, remove\n",
    "                    df_loc = df_sm.loc[df_sm['active'] == 1]\n",
    "\n",
    "#             print('kernel {}'.format(i))\n",
    "#             if i==1 and bid == 8: break\n",
    "\n",
    "            # update the trace table\n",
    "            sm_trace[sm_id] = sm_trace[sm_id].append({'sm_id': sm_id, \n",
    "                                                      'block_id': bid, \n",
    "                                                      'block_start': block_start,\n",
    "                                                      'block_end' : block_end,\n",
    "                                                      'batch_id': sms[sm_id].batch,\n",
    "                                                      'kernel_id': kern_id,\n",
    "                                                      'active': 1}, ignore_index=True)\n",
    "            \n",
    "    # return the updated sm resource and trace table\n",
    "    return sms, sm_trace\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "kern-0: start 0.0\n",
      "sm2start : 0, AfterPrevKern False\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 0 : block_start: 0.0, block_end: 0.0286245, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block False\n",
      "sm_id 1 \n",
      "to_allocate_another_block False\n",
      "\n",
      "---------------\n",
      "kern-1: start 0.057249\n",
      "sm2start : 0, AfterPrevKern True\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.0\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.0\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 0 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 1 \n",
      "to_allocate_another_block True\n",
      "kern 1 : block_start: 0.057249, block_end: 0.07156125, block_start 0.057249\n",
      "sm_id 0 \n",
      "to_allocate_another_block False\n",
      "sm_id 1 \n",
      "to_allocate_another_block False\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# run the 1st kernel\n",
    "sms, sm_trace = run_gpu_kernel(sms, sm_trace, kernels[0], 0)\n",
    "\n",
    "# run the 2nd kernel\n",
    "sms, sm_trace = run_gpu_kernel(sms, sm_trace, kernels[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>0.085874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sm_id  block_id  block_start  block_end  batch_id  kernel_id  active\n",
       "0    0.0       0.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "1    0.0       2.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "2    0.0       4.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "3    0.0       6.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "4    0.0       8.0     0.028625   0.057249       1.0        0.0     0.0\n",
       "5    0.0       0.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "6    0.0       2.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "7    0.0       4.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "8    0.0       6.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "9    0.0       8.0     0.071561   0.085874       1.0        1.0     1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_start</th>\n",
       "      <th>block_end</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>kernel_id</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>0.085874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sm_id  block_id  block_start  block_end  batch_id  kernel_id  active\n",
       "0    1.0       1.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "1    1.0       3.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "2    1.0       5.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "3    1.0       7.0     0.000000   0.028625       1.0        0.0     0.0\n",
       "4    1.0       9.0     0.028625   0.057249       1.0        0.0     0.0\n",
       "5    1.0       1.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "6    1.0       3.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "7    1.0       5.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "8    1.0       7.0     0.057249   0.071561       1.0        1.0     0.0\n",
       "9    1.0       9.0     0.071561   0.085874       1.0        1.0     1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_trace[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leiming/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAF0CAYAAACQURshAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUf8N9wW1wHNITQcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d955ab1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Plot_sm_trace(df_sm):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # color to pick\n",
    "    color_list = ['r', 'k', 'b', 'g', 'c', 'm', 'y', '#cc0000', '#cc6600', 'cc9900',\n",
    "                  '#cc3300', '#cccc00', '#99cc00', '#66cc00', '#00cccc', '#0033cc', \n",
    "                  '#6600cc', '#cc00cc', '#ff99cc', 'ffcc00']\n",
    "    \n",
    "    total_color = len(color_list) \n",
    "    \n",
    "    kern_ids = df_sm['kernel_id'].unique()\n",
    "    \n",
    "    x0_dd = {}\n",
    "    x1_dd = {}\n",
    "    y0_dd = {}\n",
    "    \n",
    "    ylim_max = 0\n",
    "    \n",
    "    for kid in kern_ids:\n",
    "        offset = 0.1 * kid\n",
    "        df_kern = df_sm.loc[df_sm['kernel_id'] == kid] # get the data for current kernel on\n",
    "        df_kern['y_axis'] = pd.Series(np.arange(1,len(df_kern.index)+1) + offset, \n",
    "                                      index=df_kern.index) # adding y_axis label\n",
    "    \n",
    "        x0_dd[kid] = df_kern['block_start']\n",
    "        x1_dd[kid] = df_kern['block_end']\n",
    "        y0_dd[kid] = df_kern['y_axis']\n",
    "\n",
    "        current_ymax = max(df_kern['y_axis']) + 1\n",
    "    \n",
    "        if ylim_max < current_ymax:\n",
    "            ylim_max = current_ymax\n",
    "    \n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, ylim_max])\n",
    "\n",
    "    for kid in kern_ids:\n",
    "        cid = int(kid) % total_color\n",
    "        plt.hlines(y0_dd[kid], x0_dd[kid], x1_dd[kid], lw=2, color=color_list[cid])\n",
    "\n",
    "    \n",
    "                                \n",
    "# #     plt.title('Memory Bound')\n",
    "    plt.xlabel('Time(clocks)')\n",
    "    plt.ylabel('Blocks')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#---------------------\n",
    "# plot\n",
    "#---------------------\n",
    "df_sm = sm_trace[0]\n",
    "\n",
    "Plot_sm_trace(df_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
